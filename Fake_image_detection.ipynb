{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random, torch, sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import ipywidgets as ipw\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils import image\n",
    "from utils.data import NumpyImageLoader\n",
    "from utils.learning import get_best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools = Pool(processes=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/serialization.py:650: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils.MobileNetV2_pretrained_imagenet import MobileNetV2\n",
    "\n",
    "params = {}\n",
    "params[\"channel\"] = \"YCbCr\"\n",
    "params[\"threshold\"] = 0.65\n",
    "params[\"training_log_dir\"] = \"backup/MBN2-YCbCr/checkpoints/\"\n",
    "\n",
    "MODEL_FILE = os.path.join(params[\"training_log_dir\"], \"model.ckpt\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MobileNetV2(n_class=2, input_size=64, width_mult=1.0).to(device=DEVICE)\n",
    "model.load(model_file=MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUploadButton():\n",
    "    myimage = ipw.FileUpload(\n",
    "        accept='',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "        multiple=False  # True to accept multiple files upload else False\n",
    "    )\n",
    "    return myimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_image(uploaded_filename):\n",
    "    IMAGE_FILE = uploaded_filename\n",
    "    GT = \"Positive\" \n",
    "    img_PIL = Image.open(IMAGE_FILE).convert(\"RGB\")\n",
    "    img = np.array(Image.open(IMAGE_FILE).convert(params[\"channel\"]))\n",
    "\n",
    "    coords, _, _ = image.slide2d(sz=img.shape[:2], K=64, S=32)\n",
    "    patches = image.crop_patches( img=img, coords=coords, patch_sz=64)\n",
    "    loader = NumpyImageLoader(ndarray_data=patches, batch_size=16, \n",
    "                              n_workers=cpu_count(), pin_memory=True, shuffle=False).loader\n",
    "\n",
    "    # Predict\n",
    "    softmaxs = []\n",
    "    model.eval()\n",
    "    for X in loader:\n",
    "        X = X[0].to(DEVICE)\n",
    "        logits = model(X)\n",
    "        softmaxs.append(F.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "    softmaxs = np.concatenate(softmaxs, axis=0)\n",
    "\n",
    "    # Post-processing\n",
    "    labels = image.post_process(softmaxs[:,1], coords, 8, params[\"threshold\"], 32, pools=pools)\n",
    "    decision = image.fusion(labels)\n",
    "    \n",
    "    fig=plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.imshow(img_PIL); plt.title(uploaded_filename); plt.axis('off')\n",
    "    if decision==1:\n",
    "        return \"Fake\"\n",
    "    else:\n",
    "        return \"Real Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea83ca994a14f9c93bb3d97a28884bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Test for document authenticity'), FileUpload(value={'payslip_1_real.jpg': {'metadaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = ipw.Text(placeholder=\"----\", layout=ipw.Layout(width=\"190px\"),  disabled=False, description='Prediction')\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import IntSlider, Output\n",
    "from IPython.display import display\n",
    "\n",
    "def on_click(btn):\n",
    "    if btn.description == \"Evaluate\":\n",
    "        try:\n",
    "            uploaded_filename = next(iter(myimage.value))            \n",
    "            content = myimage.value[uploaded_filename]['content']\n",
    "            with open(uploaded_filename, 'wb') as f: \n",
    "                f.write(content)\n",
    "            output.value = evaluate_image(uploaded_filename)\n",
    "            \n",
    "        except:\n",
    "            output.value = \"ERROR\"\n",
    "    elif btn.description == \"Clear\":\n",
    "        myimage.values = {}\n",
    "        output.value = \"\"\n",
    "        clear_output(wait=False)\n",
    "        display(pred_op)\n",
    "\n",
    "    elif btn.description == \"del\":\n",
    "        output.value = output.value[:-1]\n",
    "        \n",
    "    else:\n",
    "        output.value = output.value + btn.description\n",
    "\n",
    "def mk_btn(description):\n",
    "    btn = ipw.Button(description=description, layout=ipw.Layout(width=\"100px\" , height=\"30px\"))\n",
    "    btn.on_click(on_click)\n",
    "    return btn\n",
    "\n",
    "\n",
    "\n",
    "myimage = createUploadButton()\n",
    "label = ipw.Label(value='Test for document authenticity')\n",
    "row0 = ipw.HBox([mk_btn(\"Evaluate\") , mk_btn(\"Clear\")])\n",
    "pred_op = ipw.VBox((label, myimage, row0,  output))\n",
    "display(pred_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
